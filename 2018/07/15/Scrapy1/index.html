<!DOCTYPE html>
<html lang="en">
<head>
        <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
    <title>
        
            Scrapy Tutorial 1: overview
        
    </title>
    <link rel="icon" href="/img/favicon.png"/>
    <link rel="stylesheet" href="/css/style.css">
    <link rel="stylesheet" href="/css/font-awesome.min.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <link rel="stylesheet" href="/css/hljs.min.css">
    <script src="/js/hljs.min.js"></script>  
    <script src="/js/gitment.browser.js"></script>  
</head>
<body>
    <header class="header" id="header">
    <h1>
        <a class="title" href="/">
            Zhiqiang
        </a>
    </h1>
    <h2>
        <a class="motto">
            Be Smart and Work Hard!
        </a>
    </h2>
    <nav class="navbar">
        <ul class="menu">
            
            
                <li class="menu-item">
                    <a href="/" class="menu-item-link">
                        Home
                    </a>
                </li>
            
                
            
                <li class="menu-item">
                    <a href="/archives/" class="menu-item-link">
                        Archives
                    </a>
                </li>
            
                
            
                <li class="menu-item">
                    <a href="/about/" class="menu-item-link">
                        About
                    </a>
                </li>
            
                
            
                <li class="menu-item">
                    <a href="https://github.com/Zhiqiang-UD" class="menu-item-link">
                        Github
                    </a>
                </li>
            
                
            
                <li class="menu-item">
                    <a href="/atom.xml" class="menu-item-link">
                        RSS
                    </a>
                </li>
            
                
            
                
                
                <li class="menu-item">
                    <a class="menu-item-link search">
                        Search                   
                        <i class="fa fa-long-arrow-right search-icon" aria-hidden="true"></i>
                    </a>
                        <input placeholder="Search..." class="search-input" style="display:none;border:none!important;" onkeydown="onEnter(event)" onkeypress="onEnter(event)"></input>
                </li>
                
        </ul>
    </nav>
</header>
    <main class="main">
        <article class="post">
            <h1>
                <a class="title" href="/2018/07/15/Scrapy1/"> 
                    Scrapy Tutorial 1: overview 
                </a>
            </h1>
            <div class="meta">
                <a class="date"> 
                    <i class="fa fa-calendar" aria-hidden="true"></i>                    
                    2018-07-15   
                </a>
                
                
                
                    
            </div>
<div class="toc">
  <ol class="toc-list"><li class="toc-list-item toc-list-level-2"><a class="toc-list-link" href="#About-Scrapy"><span class="toc-list-text">About Scrapy</span></a></li><li class="toc-list-item toc-list-level-2"><a class="toc-list-link" href="#Architecture-Overview"><span class="toc-list-text">Architecture Overview</span></a><ol class="toc-list-child"><li class="toc-list-item toc-list-level-3"><a class="toc-list-link" href="#Data-Flow"><span class="toc-list-text">Data Flow</span></a></li><li class="toc-list-item toc-list-level-3"><a class="toc-list-link" href="#Components"><span class="toc-list-text">Components</span></a><ol class="toc-list-child"><li class="toc-list-item toc-list-level-4"><a class="toc-list-link" href="#Scrapy-Engine"><span class="toc-list-text">Scrapy Engine</span></a></li><li class="toc-list-item toc-list-level-4"><a class="toc-list-link" href="#Scheduler"><span class="toc-list-text">Scheduler</span></a></li><li class="toc-list-item toc-list-level-4"><a class="toc-list-link" href="#Downloader"><span class="toc-list-text">Downloader</span></a></li><li class="toc-list-item toc-list-level-4"><a class="toc-list-link" href="#Spiders"><span class="toc-list-text">Spiders</span></a></li><li class="toc-list-item toc-list-level-4"><a class="toc-list-link" href="#Item-Pipelines"><span class="toc-list-text">Item Pipelines</span></a></li><li class="toc-list-item toc-list-level-4"><a class="toc-list-link" href="#Downloader-Middleware"><span class="toc-list-text">Downloader Middleware</span></a></li><li class="toc-list-item toc-list-level-4"><a class="toc-list-link" href="#Spider-Middleware"><span class="toc-list-text">Spider Middleware</span></a></li></ol></li></ol></li><li class="toc-list-item toc-list-level-2"><a class="toc-list-link" href="#Process-to-Create-a-Scrapy-Project"><span class="toc-list-text">Process to Create a Scrapy Project</span></a><ol class="toc-list-child"><li class="toc-list-item toc-list-level-3"><a class="toc-list-link" href="#Create-Project"><span class="toc-list-text">Create Project</span></a></li><li class="toc-list-item toc-list-level-3"><a class="toc-list-link" href="#Start-with-the-First-Spider"><span class="toc-list-text">Start with the First Spider</span></a></li><li class="toc-list-item toc-list-level-3"><a class="toc-list-link" href="#Run-the-Spider"><span class="toc-list-text">Run the Spider</span></a></li></ol></li><li class="toc-list-item toc-list-level-2"><a class="toc-list-link" href="#Summary"><span class="toc-list-text">Summary</span></a></li></ol>
</div>
            <div class="content">
                <h2 id="About-Scrapy"><a href="#About-Scrapy" class="headerlink" title="About Scrapy"></a>About Scrapy</h2><blockquote>
<p><strong>Scrapy</strong>  is a free and  open source <a href="https://en.wikipedia.org/wiki/Web_crawler" target="_blank" rel="noopener">web crawling</a>   framework , written in Python. Originally designed for web scraping, it can also be used to extract data using API.  or as a general purpose web crawler. It is currently maintained by  <a href="https://en.wikipedia.org/w/index.php?title=Scrapinghub&amp;action=edit&amp;redlink=1" target="_blank" rel="noopener">Scrapinghub Ltd.</a> , a web scraping development and services company.  </p>
</blockquote>
<h2 id="Architecture-Overview"><a href="#Architecture-Overview" class="headerlink" title="Architecture Overview"></a>Architecture Overview</h2><h3 id="Data-Flow"><a href="#Data-Flow" class="headerlink" title="Data Flow"></a>Data Flow</h3><p>The following diagram shows an overview of the Scrapy architecture with its components and and outline of data flow (red arrows).<br><img src="https://doc.scrapy.org/en/latest/_images/scrapy_architecture_02.png" alt="architecture"><br>The data flow is controlled by the execution engine and goes like this (as indicated by the red arrow):</p>
<ol>
<li>The <strong>Engine</strong> gets the initial <em>Requests</em> to crawl from the <strong>Spiders</strong>.</li>
<li>The <strong>Engine</strong> schedules the <em>Requests</em> in the <strong>Scheduler</strong> and ask for the next <em>Requests</em> to crawl.</li>
<li>The <strong>Scheduler</strong> sends back the next <em>Requests</em> to the <strong>Engine</strong>.</li>
<li>The <strong>Engine</strong> send the <em>Requests</em> to the <strong>Downloader</strong> through the <strong>Downloader Middlewares</strong> (see process_request()).</li>
<li>Once the <strong>Downloader</strong> finishes the downloading it generates a <em>Response</em> and sends it back to <strong>Engine</strong> through the <strong>Downloader Middlewares</strong> (see process_response()).</li>
<li>The <strong>Engine</strong> sends the received <em>Response</em> to the <strong>Spiders</strong> for processing through the <strong>Spider Middleware</strong> (see process_spider_input()).</li>
<li>The <strong>Spiders</strong> processes the <em>Response</em> and returns the scraped <em>Items</em> and new <em>Requests</em> (to follow) to the <strong>Engine</strong> through the <strong>Spider Middleware</strong> (see process_spider_output()).</li>
<li>The <strong>Engine</strong> sends the scraped <em>Items</em> to <strong>Item Pipelines</strong>, then send the processed <em>Requests</em> to the <strong>Scheduler</strong> and ask for the next possible <em>Requests</em> to crawl.</li>
<li>The process repeats (from step 1) until there are no more requests from the <strong>Spiders</strong>.</li>
</ol>
<h3 id="Components"><a href="#Components" class="headerlink" title="Components"></a>Components</h3><h4 id="Scrapy-Engine"><a href="#Scrapy-Engine" class="headerlink" title="Scrapy Engine"></a>Scrapy Engine</h4><blockquote>
<p>The engine controls the data flow between all components and triggers events when certain action occurs. See <a href="#Data-Flow">Data Flow</a> for more details.</p>
</blockquote>
<h4 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h4><blockquote>
<p>The Scheduler receives the request from the engine and enqueues them for feeding them back to engine later when requested.</p>
</blockquote>
<h4 id="Downloader"><a href="#Downloader" class="headerlink" title="Downloader"></a>Downloader</h4><blockquote>
<p>The Downloader is responsible for fetching web pages from the Internet and feeding them back to the engine.</p>
</blockquote>
<h4 id="Spiders"><a href="#Spiders" class="headerlink" title="Spiders"></a>Spiders</h4><blockquote>
<p>Spiders are custom classes written by the user to parse responses and extract scraped items from them or additional requests to follow. Each spider is used for one (or a series of) specific webpage.</p>
</blockquote>
<h4 id="Item-Pipelines"><a href="#Item-Pipelines" class="headerlink" title="Item Pipelines"></a>Item Pipelines</h4><blockquote>
<p>The Item Pipelines is responsible for processing the extracted items from the spiders. Typical tasks include cleansing, validation and persistence (like stoing the item in a database)</p>
</blockquote>
<h4 id="Downloader-Middleware"><a href="#Downloader-Middleware" class="headerlink" title="Downloader Middleware"></a>Downloader Middleware</h4><blockquote>
<p>Downloader Middleware is a specific hook between the Engine the the Downloader and processes requests when pass from the Engine to the Downloader and responses that pass from Downloader to the Engine. It provides a simple mechanism to extend Scrapy by inserting user defined code, like automatic replace user-agent, IP, etc.</p>
</blockquote>
<h4 id="Spider-Middleware"><a href="#Spider-Middleware" class="headerlink" title="Spider Middleware"></a>Spider Middleware</h4><blockquote>
<p>Spider Middleware is a specific hook between the Engine and the Spider and processes spider input (response) and output (items and request). It also provides a simple mechanism to extend Scrapy functions by using user-defined code.</p>
</blockquote>
<h2 id="Process-to-Create-a-Scrapy-Project"><a href="#Process-to-Create-a-Scrapy-Project" class="headerlink" title="Process to Create a Scrapy Project"></a>Process to Create a Scrapy Project</h2><h3 id="Create-Project"><a href="#Create-Project" class="headerlink" title="Create Project"></a>Create Project</h3><p>First you need to create a Scrapy project. I’ll use the England Premier League website as an example. Run the following command:</p>
<pre><code class="Python">scrapy startproject EPLspider
</code></pre>
<p>The EPLspider directory with the following content will be created:</p>
<pre><code>EPLspider/
├── EPLspider
│   ├── __init__.py
│   ├── __pycache__
│   ├── items.py
│   ├── middlewares.py
│   ├── pipelines.py
│   ├── settings.py
│   └── spiders
│       ├── __init__.py
│       └── __pycache__
└── scrapy.cfg
</code></pre><p>The content of each file:</p>
<ul>
<li>EPLspider/: Python module of the project, in which code will be added.</li>
<li>EPLspider/items.py: item file of the project.</li>
<li>EPLspider/middlewares.py: middlewares file of the project.</li>
<li>EPLspider/pipelines: pipelines file of the project.</li>
<li>EPLspider/settings: settings file of the project.</li>
<li>EPLspider/spiders/: directory with spider code.</li>
<li>scrapy.cfg: configuration file of the Project.</li>
</ul>
<h3 id="Start-with-the-First-Spider"><a href="#Start-with-the-First-Spider" class="headerlink" title="Start with the First Spider"></a>Start with the First Spider</h3><blockquote>
<p>Spiders are classes that you define and that Scrapy uses to scrape information from a website (or a group of websites). They must subclass <em>scrapy.Spider</em> and define the initial request to make, optionally how to deal with links in the pages, and how to parse the downloaded page content to extract data.</p>
</blockquote>
<p>This is our first Spider, <code>EPL_spider.py</code>, saved in the directory <code>EPLspider/spiders/</code>.</p>
<pre><code>from scrapy.spiders import Spider

class EPLspider(Spider):
    name = &#39;premierLeague&#39;
    start_urls = [&#39;https://www.premierleague.com/clubs&#39;]

    def parse(self, response):
        club_url_list = response.css(&#39;ul[class=&quot;block-list-5 block-list-3-m block-list-2-s block-list-2-xs block-list-padding dataContainer&quot;] ::attr(href)&#39;).extract()
        club_name = response.css(&#39;h4[class=&quot;clubName&quot;]::text&#39;).extract()
        club_stadium = response.css(&#39;div[class=&quot;stadiumName&quot;]::text&#39;).extract()
        for i,j in zip(club_name, club_stadium):
            print(i, j)
</code></pre><h3 id="Run-the-Spider"><a href="#Run-the-Spider" class="headerlink" title="Run the Spider"></a>Run the Spider</h3><p>Run the following command in the project folder:</p>
<pre><code>scrapy crawl premierLeague
</code></pre><p>The club name and stadium of all clubs from the England Premier League will be printed out.</p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>In this tutorial we show the overall architecture of Scrapy and show its basics with a demo. In the next tutorial, we’ll extend this simple spider program to get more detailed information about the England Premier League, i.e. clubs, players, managers, and match information, <em>etc</em>.</p>

            </div>
          
           
            <div class="copyright">
                <div class="name">
                    <a>Author:</a>
                    <a>Zhiqiang Zhang</a>
                </div>
                <div class="link">
                    <a>Link:</a>
                    <a class="permalink" href="http://yoursite.com/2018/07/15/Scrapy1/">http://yoursite.com/2018/07/15/Scrapy1/</a>
                </div>
                <div class="license">
                    <a>Statement:</a>
                    <a>All articles in this blog shall be licensed by CC BY-NC-SA 3.0 CN, unless otherwise stated. Please indicate the provenance!</a>
                </div>
            </div>
            

          


</article>


<div class="tip">
<button class="tip-btn">
    Tip
</button>
<div class="tip-img">
<ul>
    
 
</ul>
</div>
</div>

<div class="more">

    <div class="prev">
   <a href="/2018/12/12/CISC_662_Project_Report/">  Parallelizing and Analysis of Shortest Path Algorithms </a>
    </div>

<div></div>

    <div class="next">
    <a href="/2018/07/13/hello-world_new/"> Hello World </a>
    </div>
    
</div>

<div class="bdsharebuttonbox">
<a href="#" class="bds_weixin fa fa-weixin" data-cmd="weixin" title="分享到微信" style="color:#1cbd8f">
</a>
<a href="#" class="bds_tsina fa fa-weibo" data-cmd="tsina" title="分享到新浪微博" style="color:#ff6363">
</a>
<a href="#" class="bds_twi fa fa-twitter" data-cmd="twi" title="分享到Twitter" style="color:#00A7EB">
</a>
<a href="#" class="bds_fbook fa fa-facebook" data-cmd="fbook" title="分享到Facebook" style="color:#00A7EB">
</a>
</div>
<script>
window._bd_share_config={
    "common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"16"},
    "share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='../../../../../static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script>
 
<div id="comments"></div>

<script>
    var gitment = new Gitment({
    id: "Sun Jul 15 2018 17:02:27 GMT-0400",
    owner: "Zhiqiang",
    repo: "Zhiqiang-UD.github.io",
    oauth: {
      client_id:"8d83609a651e972e308d",
      client_secret: "37e40c89a47e957f654e86f71c5caaccad0774de",
    }
  })
  gitment.render('comments')
</script>
    </main>
    <a class="not-found">not found!</a>
    <div class="search-items">
    </div>
    <a href="#header" id="top" style="display:none">
        <i class="fa fa-sort-asc fa-2x"></i>
    </a>
    <footer class="footer">
    <div class="footer-copyright">©️2017
    <a href="//github.com/Vevlins/toki" class="link" target="_blank">Toki</a>  by Vevlins
    </div>
</footer>

    <script src="/js/jquery.js"></script>
    <script src="/js/toki.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
</body>
</html>
